{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujUhzc6zKe1J","executionInfo":{"status":"ok","timestamp":1666198807923,"user_tz":-120,"elapsed":2372,"user":{"displayName":"Christian Ascani","userId":"06095975930704332878"}},"outputId":"01802749-8ba9-47af-f0e3-c5dde043b110"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sN_TkChDbR4_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666206422818,"user_tz":-120,"elapsed":3378,"user":{"displayName":"Christian Ascani","userId":"06095975930704332878"}},"outputId":"524dd6c5-4e9f-4cf0-fb02-9215b946b2f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n","Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"]}],"source":["%pip install pyspark"]},{"cell_type":"code","source":["import os\n","\n","from pyspark.context import SparkContext\n","from pyspark.sql.functions import lit, concat_ws, split\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql import SQLContext\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import array, lit\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import array_contains\n","\n","# se è gia esistente prende lo SparkContext, oppure lo crea\n","sc = SparkContext.getOrCreate()\n","\n","# crea una sesione nello spark Context in quanto ci possono essere più session\n","spark = SparkSession(sc)\n","\n","sqlContext = SQLContext(sc)\n","\n","schema = StructType([\n","    StructField(\"id\", StringType(), True),\n","    StructField(\"name\", StringType(), True),\n","    StructField(\"artist\", StringType(), True),\n","    StructField(\"artist_id\", StringType(), True),\n","    StructField(\"album\", StringType(), True),\n","    StructField(\"album_id\", StringType(), True),\n","    StructField(\"track_number\", IntegerType(), True),\n","    StructField(\"disk_number\", IntegerType(), True),\n","    StructField(\"explicit\", IntegerType(), True),\n","    StructField(\"danceability\", FloatType(), True),\n","    StructField(\"energy\", FloatType(), True),\n","    StructField(\"key\", IntegerType(), True),\n","    StructField(\"loudness\", FloatType(), True),\n","    StructField(\"mode\", IntegerType(), True),\n","    StructField(\"speechiness\", FloatType(), True),\n","    StructField(\"acousticness\", FloatType(), True),\n","    StructField(\"instrumentalness\", FloatType(), True),\n","    StructField(\"liveness\", FloatType(), True),\n","    StructField(\"valence\", FloatType(), True),\n","    StructField(\"tempo\", FloatType(), True),\n","    StructField(\"duration_ms\", IntegerType(), True),\n","    StructField(\"time_signature\", FloatType(), True),\n","    StructField(\"year\", IntegerType(), True),\n","    StructField(\"release_date\", StringType(), True)\n","])\n","\n","df = spark.read.format('csv').options(header=True).load(\"/content/drive/MyDrive/Colab Notebooks/Data Science/spark/trackid_artist.csv\", schema=schema)\n","\n","#df = df.filter(df.release_date == \"0000-00-00\")\n","filtered_artists = df.groupBy(\"artist\").count()\n","\n","filtered_artists = filtered_artists.filter(filtered_artists[\"count\"] > 200).dropna()\n","\n","print(filtered_artists.count())\n","artist_list = filtered_artists.select(['artist']).rdd.flatMap(lambda x: x).collect()\n","#print(artist_list)\n","\n","new_list = []\n","\n","for elem in artist_list:\n","    if (elem != 'Various Artists' & elem != 'Monstercat Call of the Wild' & elem != '\"\"Missa Sancti Josephi\"\"' & elem != ''):\n","        new_list.append(elem)\n","\n","print((new_list))\n","'''\n","out = df.filter((df.artist).isin(new_list))\n","out = out.drop(out.id).drop(out.artist_id).drop(out.album_id).drop(out.explicit).drop(out.year).dropna()\n","out.createOrReplaceTempView(\"tracks\")\n","\n","out.show(4000, truncate=False)\n","\n","#out.printSchema()\n","#print(out.count())\n","#out.coalesce(1).write.option(\"sep\",\";\").options(header=True).csv(\"./new_tracks/\")\n","'''"],"metadata":{"id":"qpMQmjq1bc0_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Artist table\n","import os\n","import pyspark\n","  \n","from pyspark.context import SparkContext\n","from pyspark.sql.functions import lit, concat_ws, split\n","from pyspark.sql.session import SparkSession\n","from pyspark.sql import SQLContext\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import array, lit\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import array_contains\n","from pyspark.sql import SparkSession\n","\n","# se è gia esistente prende lo SparkContext, oppure lo crea\n","sc = SparkContext.getOrCreate()\n","# crea una sesione nello spark Context in quanto ci possono essere più session\n","spark = SparkSession(sc)\n","\n","sqlContext = SQLContext(sc)\n","\n","schema = StructType([\n","    StructField(\"id\", StringType(), True),\n","    StructField(\"name\", StringType(), True),\n","    StructField(\"artist\", StringType(), True),\n","    StructField(\"artist_id\", StringType(), True),\n","    StructField(\"album\", StringType(), True),\n","    StructField(\"album_id\", StringType(), True),\n","    StructField(\"track_number\", IntegerType(), True),\n","    StructField(\"disk_number\", IntegerType(), True),\n","    StructField(\"explicit\", IntegerType(), True),\n","    StructField(\"danceability\", FloatType(), True),\n","    StructField(\"energy\", FloatType(), True),\n","    StructField(\"key\", IntegerType(), True),\n","    StructField(\"loudness\", FloatType(), True),\n","    StructField(\"mode\", IntegerType(), True),\n","    StructField(\"speechiness\", FloatType(), True),\n","    StructField(\"acousticness\", FloatType(), True),\n","    StructField(\"instrumentalness\", FloatType(), True),\n","    StructField(\"liveness\", FloatType(), True),\n","    StructField(\"valence\", FloatType(), True),\n","    StructField(\"tempo\", FloatType(), True),\n","    StructField(\"duration_ms\", IntegerType(), True),\n","    StructField(\"time_signature\", FloatType(), True),\n","    StructField(\"year\", IntegerType(), True),\n","    StructField(\"release_date\", StringType(), True)\n","])\n","\n","df = spark.read.format('csv').options(header=True).load(\"/content/drive/MyDrive/Colab Notebooks/Data Science/spark/trackid_artist.csv\", schema=schema)\n","\n","new_list = ['Rage Against The Machine','My Chemical Romance','The Chainsmokers','Aerosmith','Abney Park','Dua Lipa','Tokyo Blade','Ozzy Osbourne','David Bowie','Mariah Carey','Jefferson Airplane','DJ Roc','The Guess Who','Soda Stereo','Ace Frehley','Stevie Nicks','Die Flippers','Linkin Park','The Country Gentlemen','Louis Armstrong','Metallica',\n","'Electric Light Orchestra','Michael Jackson','Indochine','Zarah Leander','Circus Devils','Green Day','Taylor Dayne','Foo Fighters','Perry Como','Cher','Paul Simon','Sade','The Byrds','The Doors','Lou Reed','Dream Theater','Led Zeppelin','Dire Straits','Jimi Hendrix']\n","\n","out = df.filter((df.artist).isin(new_list))\n","out = out.drop(out.artist_id).drop(out.album_id)\n","#out.show(5000,truncate=False)\n","out.createOrReplaceTempView(\"tracks\")\n","out.coalesce(1).write.option(\"sep\",\";\").options(header=True).csv(\"/content/drive/MyDrive/Colab Notebooks/spark/toAdd/\")\n","'''\n","\n","\n","filtered_artists = df.groupBy(\"artist\").count()\n","\n","filtered_artists = filtered_artists.filter((filtered_artists[\"count\"] < 200) & (filtered_artists[\"count\"] > 100)).dropna()\n","\n","filtered_artists.orderBy(filtered_artists[\"count\"].desc()).show(5000,truncate=False)\n","\n","df2 = spark.read.format('csv').options(header=True).option(\"sep\",\";\").load(\"/content/drive/MyDrive/Colab Notebooks/spark/artists.csv\", schema=schema_artist)\n","\n","out = df1.join(df2.select('artist', 'origin'), ['artist'])\n","\n","out.createOrReplaceTempView(\"tracks\")\n","\n","out.show(5000)\n","#out.printSchema()\n","#print(out.count())\n","#df.coalesce(1).write.option(\"sep\",\";\").options(header=True).csv(\"./artists/\")\n","'''"],"metadata":{"id":"zpeQVholaFPw","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"ok","timestamp":1666206768806,"user_tz":-120,"elapsed":7515,"user":{"displayName":"Christian Ascani","userId":"06095975930704332878"}},"outputId":"d8028ddc-9753-4d57-d772-f9def545b0b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\n\\nfiltered_artists = df.groupBy(\"artist\").count()\\n\\nfiltered_artists = filtered_artists.filter((filtered_artists[\"count\"] < 200) & (filtered_artists[\"count\"] > 100)).dropna()\\n\\nfiltered_artists.orderBy(filtered_artists[\"count\"].desc()).show(5000,truncate=False)\\n\\ndf2 = spark.read.format(\\'csv\\').options(header=True).option(\"sep\",\";\").load(\"/content/drive/MyDrive/Colab Notebooks/spark/artists.csv\", schema=schema_artist)\\n\\nout = df1.join(df2.select(\\'artist\\', \\'origin\\'), [\\'artist\\'])\\n\\nout.createOrReplaceTempView(\"tracks\")\\n\\nout.show(5000)\\n#out.printSchema()\\n#print(out.count())\\n#df.coalesce(1).write.option(\"sep\",\";\").options(header=True).csv(\"./artists/\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]}]}